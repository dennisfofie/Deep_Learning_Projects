{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #load the data from tensorflow datasets\n",
    "# ds_train, ds_info = tfds.load(\n",
    "#     'celeb_a', split='test', shuffle_files=False,\n",
    "#     with_info = True, download=True\n",
    "# )\n",
    "\n",
    "# #convert it into pandas dataframe\n",
    "# ds_train_df = tfds.as_dataframe(ds_train, ds_info)\n",
    "\n",
    "# fig, ax = plt.subplot(3,3, figsize=(10,10))\n",
    "\n",
    "# for i, a in enumerate(ax.flat):\n",
    "#     image = ds_train_df['image'][i]\n",
    "#     a.imshow(image.numpy().astype(np.uint8))\n",
    "#     a.axis('off')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "#fig, axes = plt.subplot(figsize=(10,10))\n",
    "\n",
    "for index in range(10):\n",
    "    image = x_train[index]\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the images to binaries\n",
    "\n",
    "def binarize(image, label):\n",
    "    image = tf.cast(image, tf.float32)  #cast the image to float32\n",
    "    image = tf.math.round(image / 255)\n",
    "    return image, tf.cast(image, tf.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating custom layer using keras layers\n",
    "\n",
    "class MaskedConv2D(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(self)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=[self.kernel, self.kernel, input_shape[-1], self.filters],\n",
    "                    initializer='glorot_normal', trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.filters,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        \n",
    "        mask = np.ones(self.kernel ** 2, dtype=np.float32)\n",
    "        center = len(mask) / 2\n",
    "\n",
    "        mask[center+1:] = 0\n",
    "\n",
    "        if self.mask_type == 'A':\n",
    "            mask[center] = 0\n",
    "\n",
    "        mask = mask.reshape((self.kernel, self.kernel, 1,1))\n",
    "        self.mask = tf.constant(mask, dtype='float32')\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        masked_w = tf.math.multiply(self.w, self.mask)\n",
    "        output = tf.nn.conv2d(inputs, masked_w, 1, 'SAME') + self.b\n",
    "\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
